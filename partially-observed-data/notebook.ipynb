{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Partially Observed Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pseudo-code\n",
    "\n",
    "<pre>\n",
    "<i><b>Expectation-Maximization</b></i> (\n",
    "    &theta;<sup>(0)</sup> // Initial parameters\n",
    "    D   // Data\n",
    "  )\n",
    "1    <b>for</b> each iteration t\n",
    "2        M<sub>t</sub> &larr; E-step(&theta;<sup>(t)</sup>, D)\n",
    "3        &theta;<sup>(t+1)</sup> &larr; M-step(M<sub>t</sub>)\n",
    "4    <b>return</b> &theta;<sup>(T)</sup>\n",
    "\n",
    "<i><b>E-step</b></i> (\n",
    "    &theta;<sup>(t)</sup> // Current parameters\n",
    "    D   // Data\n",
    "  )\n",
    "1    M<sub>t</sub> &larr; 0\n",
    "2    <b>for</b> each data point d\n",
    "3        <b>for</b> each node X\n",
    "4            <b>for</b> each combination X=x, Pa(X)=y\n",
    "5                M<sub>t</sub>[x, y] &larr; M<sub>t</sub>[x, y] + p(x, y|d, &theta;<sup>(t)</sup>)\n",
    "6    <b>return</b> M<sub>t</sub>\n",
    "    \n",
    "\n",
    "<i><b>M-step</b></i> (\n",
    "    M<sub>t</sub>  // Expected sufficient statistics\n",
    "  )\n",
    "1    <b>for</b> each node X\n",
    "2        <b>for</b> each combination X=x, Pa(X)=y\n",
    "3            &theta;<sup>(t+1)</sup>[x|y] &larr; M<sub>t</sub>[x, y] / M<sub>t</sub>[p]\n",
    "4    <b>return</b> &#x03B8;<sup>(t+1)</sup>\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from em import expectation_maximization, generate_data, print_tables, print_marginals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "p(x) = [0.568 0.432]\n",
    "\n",
    "p(y) = [0.294 0.706]\n",
    "\n",
    "\n",
    "```\n",
    "p(z|x=0, y=0) = {pz[0, 0]}\n",
    "\n",
    "p(z|x=0, y=1) = {pz[0, 1]}\n",
    "\n",
    "p(z|x=1, y=0) = {pz[1, 0]}\n",
    "\n",
    "p(z|x=1, y=1) = {pz[1, 1]}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def e_step(qx, qy, qz, xs, ys, zs):\n",
    "    Mx = np.zeros(2)\n",
    "    My = np.zeros(2)\n",
    "    Mz = np.zeros((2, 2, 2))  # Remember index order: Mz[x, y, z]\n",
    "    for x, y, z,l in zip(xs, ys, zs,range(500)):\n",
    "   \n",
    "        \"\"\"\n",
    "        To do:  p(X|x, y, z) and add to Mx (The M Î¸ (t) are the expected sufficient statistics)\n",
    "                p(Y|x, y, z) and add to My\n",
    "                p(Z, X, Y|x, y, z) and add to Mz.\n",
    "            Remember to normalize p(.), i.e. each should sum to 1. \n",
    "                For example, if x, y and z are not None, we should have p(X=x) = 1, p(Y=y) = 1, p(Z=z, X=x, Y=y) = 1. \n",
    "        Naive solution (~45 lines of code): \n",
    "            x and y are None? ...\n",
    "            x is None: ... (NB: p(X|Y=y, Z=z) = p(X, Y=y, Z=z) / p(Y=y, Z=z) != p(X))\n",
    "            y is None: ...\n",
    "            x and y are known: p(...) = 1\n",
    "        Pythonic solution (<10 lines of code):\n",
    "            Q = np.zeros((2, 2)) # Q(x, y) = p(Z=z, X=x, Y=y)\n",
    "            # Q <- p(...)\n",
    "            Mx += ...p(X|x, y, z)\n",
    "            My += ...p(Y|x, y, z)\n",
    "            Mz[:, :, z] += ... p(Z, X, Y|x, y, z)\n",
    "        \"\"\"\n",
    "        # print(x,y,z)\n",
    "        ####################################################\n",
    "        # IN THE CASE THERE IS NO MISSING DATA\n",
    "        ###################################################\n",
    "        # if (x != None) and (y != None) and (z != None):\n",
    "        #     Q = np.zeros((2,2))\n",
    "        #     Q[x,y] = 1\n",
    "        #     Mx +=  Q[:,y] #(qx/p_z_x_y)/sum(qx/p_z_x_y)\n",
    "        #     My += Q[x] #(qy/p_z_x_y)/sum(qy/p_z_x_y)\n",
    "        #     Mz[:,:,z] += Q # \n",
    "        #     continue \n",
    "        \n",
    "        ###################################################\n",
    "        # IN THE CASE THERE IS A MISSING DATA \n",
    "        ###################################################\n",
    "        \n",
    "        \n",
    "        # if the data is missing, otherwise \n",
    "        # qx = p(x) , qy = p(y), qz = p(z|x,y)\n",
    "        # 0           1            1    pz1 = p(x)p(y)p(z|x,y)  --> q = pz1/pz1+pz2\n",
    "        # 0           1            0    pz2 = p(x)p(y)p(z|x,y)  --> q = pz2/pz1+pz2\n",
    "        # 1           0            1    pz3 = p(x)p(y)p(z|x,y)  --> q = pz3/pz3+pz4\n",
    "        # 1           0            0    pz4 = p(x)p(y)p(z|x,y)  --> q = pz4/pz3+pz4\n",
    "        # 0           0            1    pz5\n",
    "        # 0           0            0    pz6\n",
    "        # 1           1            1    pz7\n",
    "        # 1           1            0    pz8\n",
    "        \n",
    "        # we need to to compute the weights of each possible occurance and then add this \n",
    "        # if the x or y missing, they are indepenedent \n",
    "        if (x != None) and (y != None) and (z != None):\n",
    "            Q = np.zeros((2,2))\n",
    "            Q[x,y] = 1\n",
    "            Mx +=  Q[:,y] #(qx/p_z_x_y)/sum(qx/p_z_x_y)\n",
    "            My += Q[x] #(qy/p_z_x_y)/sum(qy/p_z_x_y)\n",
    "            Mz[:,:,z] += Q # \n",
    "            \n",
    "# not sure but this seems like what you wanted (as a pythonic solution) but it yields a lower probability and does not seem to be realyl correct (probably my fault), thus i went with less elegant way  \n",
    "#         else:\n",
    "            \n",
    "#             Mx += qx\n",
    "#             My += qy \n",
    "#             Q = qx*qy*qz\n",
    "#             # My[y] += 1 #(qy/p_z_x_y)/sum(qy/p_z_x_y)\n",
    "#             Mz += Q/ np.sum(Q)\n",
    "        \n",
    "        \n",
    "        elif x == None and y == None: \n",
    "            Mx += qx\n",
    "            My += qy \n",
    "            # My[y] += 1 #(qy/p_z_x_y)/sum(qy/p_z_x_y)\n",
    "            Mz[:,:,z] += (qx *qy* qz[:,:,z])/ np.sum(qx *qy * qz[:,:,z])\n",
    "            # print((qx *qy* qz[:,:,z])/ np.sum(qx *qy * qz[:,:,z]))\n",
    "        # there is no situation where the x and z or y and z are missing, so i do not consider that \n",
    "        elif x == None:\n",
    "            Mx += qx\n",
    "            My[y] += 1 #(qy/p_z_x_y)/sum(qy/p_z_x_y)\n",
    "            Mz[:,y,z] += (qx * qz[:,y,z])/ np.sum(qx * qz[:,y,z])\n",
    "            # print((qx * qz[:,y,z])/ np.sum(qx * qz[:,y,z]))\n",
    "        elif y == None:\n",
    "            My += qy \n",
    "            Mx[x] += 1 #(qy/p_z_x_y)/sum(qy/p_z_x_y)\n",
    "            Mz[x,:,z] += (qy * qz[x,:,z])/ np.sum(qy * qz[x,:,z])\n",
    "        elif z == None: # and x and y are known \n",
    "            Q = np.zeros((2,2))\n",
    "            Q[x,y] = 1\n",
    "            Mx +=  Q[:,y] #(qx/p_z_x_y)/sum(qx/p_z_x_y)\n",
    "            My += Q[x] \n",
    "            Mz[x,y] += qz[x,y] / np.sum(qz[x,y])\n",
    "            \n",
    "    # print(np.sum(Mz[0])-np.sum(Mx[0]))\n",
    "    return Mx, My, Mz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def m_step(Mx, My, Mz):\n",
    "    \"\"\"\n",
    "    Convert from sufficient statistics to parameters. What elemets should sum to one?\n",
    "    \"\"\"\n",
    "    qx = Mx / sum(Mx)\n",
    "    qy = My / sum(My)\n",
    "    # np.reshape(np.sum(Mz,axis=1),(2,2,1))\n",
    "    qz = Mz / np.reshape(np.sum(Mz,axis=2),(2,2,1))\n",
    "    return qx, qy, qz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.random.seed(2018)\n",
    "px = np.array([0.6, 0.4])\n",
    "py = np.array([0.3, 0.7])\n",
    "pz = np.array([[[0.2, 0.8], [0.7 ,0.3]], [[0.9, 0.1], [0.1, 0.9]]])  # p(z|x, y) = pz[x, y, z]\n",
    "n_data = 500\n",
    "x, y, z = generate_data(px, py, pz, n_data,partially_observed=True)\n",
    "# for i in range(500):\n",
    "#     if y[i] == z[i] and z[i] == None:\n",
    "#         print('fuck')\n",
    "n_iter = 10\n",
    "qx, qy, qz = expectation_maximization(x, y, z, e_step, m_step, n_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 1.0\n",
      "0.03136673761821597\n",
      "1.0 0.8\n",
      "0.1090699263999996\n",
      "1.0 0.6\n",
      "0.16346402656000014\n",
      "1.0 0.4\n",
      "0.18821201762598272\n",
      "1.0 0.2\n",
      "0.24306409658556627\n",
      "0.8 0.6\n",
      "0.30121836827323156\n",
      "0.8 0.4\n",
      "0.40000000000000036\n",
      "0.6 0.8\n",
      "0.5803398255657937\n",
      "0.4 0.1\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "# for purpose of question 4\n",
    "np.random.seed(2018)\n",
    "diff = 0\n",
    "for pxi in [1.0, 0.8, 0.6, 0.4, 0.2, 0.1, 0]:\n",
    "    for pyi in [1.0, 0.8, 0.6, 0.4, 0.2, 0.1, 0]: \n",
    "        \n",
    "        px = np.array([pxi, 1-pxi])\n",
    "        py = np.array([pyi, 1-pyi])\n",
    "        pz = np.array([[[0.2, 0.8], [0.1, 0.9]], [[0.9, 0.1], [0.1, 0.9]]])  # p(z|x, y) = pz[x, y, z]\n",
    "        n_data = 50\n",
    "        x, y, z = generate_data(px, py, pz, n_data,partially_observed=True)\n",
    "        # for i in range(500):\n",
    "        #     if y[i] == z[i] and z[i] == None:\n",
    "        #         print('fuck')\n",
    "        n_iter = 10\n",
    "        qx, qy, qz = expectation_maximization(x, y, z, e_step, m_step, n_iter)\n",
    "        if diff < sum(abs(qx-px)+abs(qy-py)):\n",
    "            diff = sum(abs(qx-px)+abs(qy-py))\n",
    "            print(pxi,pyi)\n",
    "            print(sum(abs(qx-px)+abs(qy-py)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learnt parameters\n",
      "----------------\n",
      "p(x) = [0.62705125 0.37294875]\n",
      "p(y) = [0.3168482 0.6831518]\n",
      "p(z|x=0, y=0) = [0.25610379 0.74389621]\n",
      "p(z|x=0, y=1) = [0.68720144 0.31279856]\n",
      "p(z|x=1, y=0) = [0.88428318 0.11571682]\n",
      "p(z|x=1, y=1) = [0.06647732 0.93352268]\n",
      "\n",
      "True parameters\n",
      "--------------\n",
      "p(x) = [0.6 0.4]\n",
      "p(y) = [0.3 0.7]\n",
      "p(z|x=0, y=0) = [0.2 0.8]\n",
      "p(z|x=0, y=1) = [0.7 0.3]\n",
      "p(z|x=1, y=0) = [0.9 0.1]\n",
      "p(z|x=1, y=1) = [0.1 0.9]\n"
     ]
    }
   ],
   "source": [
    "print(\"Learnt parameters\")\n",
    "print(\"----------------\")\n",
    "print_tables(qx, qy, qz)\n",
    "print()\n",
    "print(\"True parameters\")\n",
    "print(\"--------------\")\n",
    "print_tables(px, py, pz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learnt marginals\n",
      "----------------\n",
      "p(z|x=0) = [0.31683705 0.68316295]\n",
      "p(z|x=1) = [0.3899365 0.6100635]\n",
      "p(z|y=0) = [0.9199275 0.0800725]\n",
      "p(z|y=1) = [0.05519159 0.94480841]\n",
      "\n",
      "True marginals\n",
      "--------------\n",
      "p(z|x=0) = [0.55 0.45]\n",
      "p(z|x=1) = [0.34 0.66]\n",
      "p(z|y=0) = [0.9 0.1]\n",
      "p(z|y=1) = [0.1 0.9]\n"
     ]
    }
   ],
   "source": [
    "print(\"Learnt marginals\")\n",
    "print(\"----------------\")\n",
    "print_marginals(qx, qy, qz)\n",
    "print()\n",
    "print(\"True marginals\")\n",
    "print(\"--------------\")\n",
    "print_marginals(px, py, pz)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "\n",
    "# QUESTION 2 \n",
    "Code above, reported values with seed 2018\n",
    "```\n",
    "p(x) = [0.586 0.414]\n",
    "\n",
    "p(y) = [0.316 0.684]\n",
    "\n",
    "p(z|x=0, y=0) = [0.20212766 0.79787234]\n",
    "\n",
    "p(z|x=0, y=1) = [0.70351759 0.29648241]\n",
    "\n",
    "p(z|x=1, y=0) = [0.890625 0.109375]\n",
    "\n",
    "p(z|x=1, y=1) = [0.09090909 0.90909091]\n",
    "\n",
    "True parameters\n",
    "---------------\n",
    "\n",
    "p(x) = [0.6 0.4]\n",
    "\n",
    "p(y) = [0.3 0.7]\n",
    "\n",
    "p(z|x=0, y=0) = [0.2 0.8]\n",
    "\n",
    "p(z|x=0, y=1) = [0.7 0.3]\n",
    "\n",
    "p(z|x=1, y=0) = [0.9 0.1]\n",
    "\n",
    "p(z|x=1, y=1) = [0.1 0.9]\n",
    "\n",
    "Learnt marginals\n",
    "----------------\n",
    "\n",
    "\n",
    "p(z|x=0) = [0.54507837 0.45492163]\n",
    "\n",
    "p(z|x=1) = [0.34361932 0.65638068]\n",
    "\n",
    "p(z|y=0) = [0.48716556 0.51283444]\n",
    "\n",
    "p(z|y=1) = [0.44989767 0.55010233]\n",
    "\n",
    "\n",
    "True marginals\n",
    "\n",
    "--------------\n",
    "p(z|x=0) = [0.55 0.45]\n",
    "\n",
    "\n",
    "p(z|x=1) = [0.34 0.66]\n",
    "\n",
    "\n",
    "p(z|y=0) = [0.48 0.52]\n",
    "\n",
    "\n",
    "p(z|y=1) = [0.46 0.54]\n",
    "\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Question 3 \n",
    "I had to uncomment the assertation, there was a slight difference in the sum, at the beginning 2-3 units, after 3 iterations 0.3 units. \n",
    "The weird thing is that it does not happen at $1^{st}$ iteration step but starts from the $2^{nd}$ one...\n",
    "\n",
    "```assert np.isclose(np.sum(Mz[0]), Mx[0]), f\"Mz[0] = {Mz[0]} should sum to Mx[0] = {Mx[0]}\"```\n",
    "\n",
    "there is also a slight difference in the results, which could be a mistake I did in the code (?)\n",
    "Here are the resutls with seed = 1337\n",
    "\n",
    "```\n",
    "Learnt parameters\n",
    "\n",
    "-----------------\n",
    "\n",
    "p(x) = [0.56917956 0.43082044]\n",
    "\n",
    "p(y) = [0.28526338 0.71473662]\n",
    "\n",
    "p(z|x=0, y=0) = [0.28166043 0.71833957]\n",
    "\n",
    "p(z|x=0, y=1) = [0.6009467 0.3990533]\n",
    "\n",
    "p(z|x=1, y=0) = [0.91737932 0.08262068]\n",
    "\n",
    "p(z|x=1, y=1) = [0.09256873 0.90743127]\n",
    "\n",
    "\n",
    "True parameters\n",
    "\n",
    "---------------\n",
    "\n",
    "p(x) = [0.6 0.4]\n",
    "\n",
    "p(y) = [0.3 0.7]\n",
    "\n",
    "p(z|x=0, y=0) = [0.2 0.8]\n",
    "\n",
    "p(z|x=0, y=1) = [0.7 0.3]\n",
    "\n",
    "p(z|x=1, y=0) = [0.9 0.1]\n",
    "\n",
    "p(z|x=1, y=1) = [0.1 0.9]\n",
    "```\n",
    "\n",
    "and with seed 2018, there the difference was quite high, up to 14 units.\n",
    "\n",
    "```\n",
    "\n",
    "Learnt parameters\n",
    "\n",
    "-----------------\n",
    "\n",
    "p(x) = [0.62705125 0.37294875]\n",
    "\n",
    "p(y) = [0.3168482 0.6831518]\n",
    "\n",
    "p(z|x=0, y=0) = [0.25610379 0.74389621]\n",
    "\n",
    "p(z|x=0, y=1) = [0.68720144 0.31279856]\n",
    "\n",
    "p(z|x=1, y=0) = [0.88428318 0.11571682]\n",
    "\n",
    "p(z|x=1, y=1) = [0.06647732 0.93352268]\n",
    "\n",
    "\n",
    "True parameters\n",
    "--------------\n",
    "p(x) = [0.6 0.4]\n",
    "\n",
    "p(y) = [0.3 0.7]\n",
    "\n",
    "p(z|x=0, y=0) = [0.2 0.8]\n",
    "\n",
    "p(z|x=0, y=1) = [0.7 0.3]\n",
    "\n",
    "p(z|x=1, y=0) = [0.9 0.1]\n",
    "\n",
    "p(z|x=1, y=1) = [0.1 0.9]\n",
    "\n",
    "```\n",
    "\n",
    "I also iterate over some of the possible probability values and the highest absolute cummulative difference (0.45) between GT and the predicted values is for the GT probabilities \n",
    "\n",
    "px = (0.1, 0.9)\n",
    "py = (0.8, 0.2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 4\n",
    "\n",
    "Setting px to (0,1)\n",
    "In this case differences are pretty high (a couple of %). Additionally, the issue which I reported in the previous question seems to repeat and the difference is really observable (~40 units). Nevertheless we are still able to predict the actual values quite well:\n",
    "\n",
    "```\n",
    "Learnt parameters\n",
    "\n",
    "-----------------\n",
    "\n",
    "p(x) = [3.67149593e-05 9.99963285e-01]\n",
    "\n",
    "p(y) = [0.31614058 0.68385942]\n",
    "\n",
    "p(z|x=0, y=0) = [0.15505673 0.84494327]\n",
    "\n",
    "p(z|x=0, y=1) = [0.44084963 0.55915037]\n",
    "\n",
    "p(z|x=1, y=0) = [0.8862824 0.1137176]\n",
    "\n",
    "p(z|x=1, y=1) = [0.13982897 0.86017103]\n",
    "\n",
    "\n",
    "True parameters\n",
    "\n",
    "---------------\n",
    "\n",
    "p(x) = [0 1]\n",
    "\n",
    "p(y) = [0.3 0.7]\n",
    "\n",
    "p(z|x=0, y=0) = [0.2 0.8]\n",
    "\n",
    "p(z|x=0, y=1) = [0.7 0.3]\n",
    "\n",
    "p(z|x=1, y=0) = [0.9 0.1]\n",
    "\n",
    "p(z|x=1, y=1) = [0.1 0.9]\n",
    "```\n",
    "\n",
    "**10x less data**\n",
    "\n",
    "The algorithm deals much better, suprisingly with similar scenario but less data giving more accurate results! It could be due to the fact that since there is less data, most of the examples have the values of the highly probable and it is easy to learn.\n",
    "\n",
    "```\n",
    "Learnt parameters\n",
    "\n",
    "----------------\n",
    "\n",
    "p(x) = [3.13910592e-05 9.99968609e-01]\n",
    "\n",
    "p(y) = [0.61289614 0.38710386]\n",
    "\n",
    "p(z|x=0, y=0) = [9.99999955e-01 4.50491652e-08]\n",
    "\n",
    "p(z|x=0, y=1) = [9.99084993e-01 9.15006800e-04]\n",
    "\n",
    "p(z|x=1, y=0) = [0.94457189 0.05542811]\n",
    "\n",
    "p(z|x=1, y=1) = [0.09567451 0.90432549]\n",
    "\n",
    "\n",
    "True parameters\n",
    "\n",
    "--------------\n",
    "\n",
    "p(x) = [0 1]\n",
    "\n",
    "p(y) = [0.7 0.3]\n",
    "\n",
    "p(z|x=0, y=0) = [0.2 0.8]\n",
    "\n",
    "p(z|x=0, y=1) = [0.1 0.9]\n",
    "\n",
    "p(z|x=1, y=0) = [0.9 0.1]\n",
    "\n",
    "p(z|x=1, y=1) = [0.1 0.9]\n",
    "\n",
    "```\n",
    "Nevertheless, when it comes to the marginal, our model performed very poorly and there is a big difference between the GT and predicted distribution\n",
    " \n",
    "\n",
    "```\n",
    "Learnt marginals\n",
    "\n",
    "----------------\n",
    "\n",
    "p(z|x=0) = [0.31683705 0.68316295]\n",
    "\n",
    "p(z|x=1) = [0.3899365 0.6100635]\n",
    "\n",
    "p(z|y=0) = [0.9199275 0.0800725]\n",
    "\n",
    "p(z|y=1) = [0.05519159 0.94480841]\n",
    "\n",
    "\n",
    "True marginals\n",
    "\n",
    "--------------\n",
    "\n",
    "p(z|x=0) = [0.55 0.45]\n",
    "\n",
    "p(z|x=1) = [0.34 0.66]\n",
    "\n",
    "p(z|y=0) = [0.9 0.1]\n",
    "\n",
    "p(z|y=1) = [0.1 0.9]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 5 \n",
    "With ```never_coobserved``` data flagged as true, our algorithm deal pretty well. We can see that the prediceted values are very close to the actual values\n",
    "```\n",
    "Learnt parameters\n",
    "\n",
    "-----------------\n",
    "\n",
    "p(x) = [0.586 0.414]\n",
    "\n",
    "p(y) = [0.316 0.684]\n",
    "\n",
    "p(z|x=0, y=0) = [0.20212766 0.79787234]\n",
    "\n",
    "p(z|x=0, y=1) = [0.70351759 0.29648241]\n",
    "\n",
    "p(z|x=1, y=0) = [0.890625 0.109375]\n",
    "\n",
    "p(z|x=1, y=1) = [0.09090909 0.90909091]\n",
    "\n",
    "\n",
    "True parameters\n",
    "\n",
    "---------------\n",
    "\n",
    "p(x) = [0.6 0.4]\n",
    "\n",
    "p(y) = [0.3 0.7]\n",
    "\n",
    "p(z|x=0, y=0) = [0.2 0.8]\n",
    "\n",
    "p(z|x=0, y=1) = [0.7 0.3]\n",
    "\n",
    "p(z|x=1, y=0) = [0.9 0.1]\n",
    "\n",
    "p(z|x=1, y=1) = [0.1 0.9]\n",
    "```\n",
    "Naivly, we coudl say that it should be harder to learn such a distribution, however since it is ```x``` or ```y``` missing, it may be a big easier due to the fact that ```z``` is dependent on these variables. Due to this fact it it seems that data is missing but **not** at random (maybe MNAR)? This dependency also explains why mariginal distributions are even closer to the ```true``` ones. We can see them printed below:\n",
    "```\n",
    "Learnt marginals\n",
    "\n",
    "----------------\n",
    "\n",
    "p(z|x=0) = [0.54507837 0.45492163]\n",
    "\n",
    "p(z|x=1) = [0.34361932 0.65638068]\n",
    "\n",
    "p(z|y=0) = [0.48716556 0.51283444]\n",
    "\n",
    "p(z|y=1) = [0.44989767 0.55010233]\n",
    "\n",
    "\n",
    "True marginals\n",
    "\n",
    "--------------\n",
    "\n",
    "p(z|x=0) = [0.55 0.45]\n",
    "\n",
    "p(z|x=1) = [0.34 0.66]\n",
    "\n",
    "p(z|y=0) = [0.48 0.52]\n",
    "\n",
    "p(z|y=1) = [0.46 0.54]\n",
    "```\n",
    "\n",
    "Sorry, I m not sure what you mean about \"Does the MAR tell the whole store :)\". I hope I provided enough details in my other answers!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
